---
layout: post
title: 对网络库glue进行测试
date: 2016-09-21 19:44
categories: programming
tags: [cpp, network]
---

#### 测试环境

**一台4核2.5GHz的笔记本**

#### 吞吐量测试

##### 测试方法
使用glue设计ping-pong server和ping-pong client，由client首先向server发送数据块（16K or 48K），server收到后将其发送回client，而client则将其再发送给server，一直传送直到定时器timeout，统计每个client所收到的的字节数，再除以时间则为吞吐量的值。由于主机为4核，因此server和client各指定2个线程，指定再多线程实际作用的也只有4个线程，而且会增加线程切换的时间。

##### 测试结果

![](/assets/images/throughput-performance.bmp)

从图中可以看出， 随着并发的clients的数目增加，吞吐量有所下降，可以归结于epoll的内部实现，活动的clients增加会导致epoll_wait返回时需要从内核拷贝到用户态的文件描述符信息增加，同时，在一次循环中需要处理的事件数量增加，因此处理事件时间变长，但是由于用户数增加，所传送数据也会增加，因此整个的吞吐量也不会太低。从图中可以看到，当客户端并发连接数为20000时，ping-pong server也有将近1GiB/s的吞吐量。

#### 事件处理时间测试

##### 测试方法
所用程序是来自libevent源码中test/bench.cc, 根据glue的实现做了相应修改。程序基本的逻辑链路是，使用一个文件描述符数组，每2个文件描述由socketpair（）产生，且为unix socket。整个程序的触发逻辑是向每个pipe的可写文件描述符发送字符，收到字符的可读端则向下一个pipe的可写端写入，一直这样循环，直到所有文件描述符的被写次数达到预设值才停止。计算此过程的时间则为事件处理时间，通过此时间来反应网络库对事件处理的灵敏度。

##### 测试结果

![](/assets/images/event-process-100-clients.bmp)

![](/assets/images/event-process-1000-clients.bmp)

通过上面两幅图可以看出，glue的事件处理时间在100和1000个clients中均少于libevent处理相应事件所需要的时间。

#### 问题记录

整个网络库都是基于reactor的模式来实现的，因此需要将事件逻辑以回调函数的方式来传递，不可避免的需要使用bind函数来对相应参数进行绑定，bind生成的functor对象内部有一个成员存储相应参数，该成员则以参数来进行构造，相当于是对输入参数进行拷贝，因此对于非指针对象应该以此对象的地址或者引用进行传输，比如glue中的Buffer对象在进行绑定时可以使用std::ref(buf)来进行传输，std::ref(buf) 会生成一个reference\_wrapper object, 此object里面将会有一个成员为buf的引用，因此所生成的functor对象内部将会有相应的reference\_wrapper object来间接对buf引用。

**std::ref(T)的作用** 对于常见的引用（T&），不能被数组或者容器进行存储，而std::ref(T)可以; std::ref(T)内部存在一个`operator &T() const noexcept`转换函数，因此std::ref(T)又可以被用在任何类型为T&的地方。
